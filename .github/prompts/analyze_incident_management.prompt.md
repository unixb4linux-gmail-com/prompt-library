---
title: "Analyze Incident Management Setup"
category: "SRE & Incident Response"
description: "Audit incident management processes, tools, alerting, escalation policies, and response procedures for SRE best practices"
author: "claude-code"
---

**Best Practices:**
- Ask clarifying questions before proceeding if any requirements or context are unclear.
- Ask for permission before running commands, editing, or creating files. Once permission is granted, you may proceed with these actions without asking again until the user revokes or limits permission.

> **Context Management:**
> If the incident management setup is too complex for comprehensive analysis, prioritize:
> 1. Security-critical alerting configurations and escalation policy effectiveness
> 2. Production incident response workflows and communication procedures
> 3. Integration effectiveness between monitoring, alerting, and response tools
> Ask user to specify focus areas if scope exceeds analysis capacity.

> **Analysis Validation:**
> - Mark findings as "Confirmed" vs "Potential" based on platform configuration evidence and response procedure documentation
> - Reference specific alerting rules, escalation policies, or integration setups when citing findings
> - Provide confidence indicators: High/Medium/Low for each incident management and SRE recommendation
> - Note when additional platform access or incident history data would improve analysis accuracy

**Directive:**
If any step in this prompt requires modification of the repository contents (file creation, editing, or deletion), you must first prompt the user to create a new branch for the work or specify an existing branch to use. Only proceed with changes after the user provides direction.

Before making changes, check which branch is currently checked out. Check if the branch is up to date with its remote. If the branch is current, offer to continue. If it is not current, offer to sync (pull) the branch before continuing.

# ğŸš¨ Analyze Incident Management Setup

You are a senior SRE and incident response expert. Your task is to evaluate the incident management capabilities, processes, and tooling in this environment.

## Step 1: Discovery & Assessment

Ask the user to clarify:
- "Which incident management platform are you using (PagerDuty, Opsgenie, VictorOps, custom)?"
- "Do you have access to alerting configurations (Prometheus AlertManager, monitoring tools)?"
- "Are there existing incident response playbooks or runbooks to review?"

## Step 2: Incident Management Platform Analysis

### ğŸ“‹ Platform Configuration Review

Analyze the incident management platform setup:

| **Component** | **Purpose** |
|---------------|-------------|
| **Services** | Service definitions, dependencies, ownership |
| **Escalation Policies** | On-call schedules, escalation tiers, timeout rules |
| **Notification Rules** | Alert routing, notification channels, filtering |
| **Integrations** | Monitoring tools, ChatOps, ITSM systems |

### ğŸ”„ Alert Configuration Assessment

* **Alert Sources**: Prometheus, CloudWatch, DataDog, Nagios, custom webhooks
* **Alert Routing**: Service mapping, severity levels, suppression rules
* **Notification Channels**: Email, SMS, Slack, phone calls, mobile push
* **Alert Fatigue Management**: Deduplication, rate limiting, intelligent grouping

## Step 3: Incident Response Process Evaluation

### ğŸ“– Runbooks & Playbooks

* **Coverage**: Are runbooks available for common incident types?
* **Accessibility**: Are runbooks easily discoverable during incidents?
* **Currency**: When were runbooks last updated and tested?
* **Automation**: Are manual steps automated or scriptable?

### ğŸ¯ Response Procedures

* **Incident Classification**: Severity levels (P0/P1/P2/P3/P4)
* **Communication Plans**: Status updates, stakeholder notifications
* **Escalation Triggers**: Automatic escalation criteria and timing
* **Resolution Tracking**: SLA adherence, resolution times

## Step 4: On-Call Management Assessment

### ğŸ‘¥ On-Call Structure

* **Rotation Schedule**: Primary/secondary, follow-the-sun coverage
* **Handoff Procedures**: Shift changes, knowledge transfer
* **Coverage Gaps**: Holiday coverage, backup arrangements
* **Workload Distribution**: Fair rotation, burn-out prevention

### ğŸ“Š On-Call Health Metrics

* **Alert Volume**: Alerts per engineer per shift
* **Response Times**: Acknowledgment and resolution SLAs
* **Escalation Rate**: Percentage of alerts requiring escalation
* **False Positive Rate**: Alert accuracy and noise reduction

## Step 5: Post-Incident Analysis

### ğŸ” Incident Reviews

* **Post-Mortem Process**: Blameless culture, structured templates
* **Root Cause Analysis**: 5-whys, fishbone diagrams, timeline reconstruction
* **Action Items**: Tracking, ownership, completion rates
* **Learning Dissemination**: Knowledge sharing, training updates

### ğŸ“ˆ Incident Metrics & Reporting

* **MTTD** (Mean Time To Detection): Alert effectiveness
* **MTTR** (Mean Time To Resolution): Response efficiency  
* **MTBF** (Mean Time Between Failures): System reliability
* **Incident Trends**: Frequency, patterns, repeat issues

## Step 6: Integration & Automation Assessment

### ğŸ”— Tool Integrations

* **ChatOps**: Slack/Teams incident channels, bot commands
* **ITSM**: Jira, ServiceNow ticket creation and updates
* **Monitoring**: Bi-directional sync with observability tools
* **Status Pages**: Automatic status updates, customer communication

### ğŸ¤– Automation Opportunities

* **Auto-Resolution**: Self-healing for known issues
* **Alert Enrichment**: Context injection, related metrics
* **Communication**: Automated status updates, notifications
* **Remediation**: Automated rollbacks, traffic routing

## Output Format

Respond using the following structured format:

```markdown
## ğŸš¨ Incident Management Analysis

### ğŸ“‹ Platform Configuration
- **Strengths**: Well-configured areas
- **Weaknesses**: Configuration gaps or issues

### ğŸ”„ Alert Management
- **Coverage**: Alert source coverage assessment  
- **Quality**: Alert signal-to-noise ratio
- **Routing**: Effectiveness of alert routing rules

### ğŸ“– Response Procedures
- **Runbooks**: Quality and coverage of documentation
- **Processes**: Incident response workflow evaluation
- **Training**: Team preparedness assessment

### ğŸ‘¥ On-Call Management
- **Structure**: On-call rotation effectiveness
- **Workload**: Sustainable alert volume analysis
- **Support**: Tools and resources for on-call engineers

### ğŸ“Š Metrics & Improvement
- **Current Performance**: MTTD, MTTR, incident trends
- **Gaps**: Missing metrics or reporting
- **Recommendations**: Specific improvement actions

### ğŸ”— Integration & Automation
- **Current State**: Existing integrations assessment
- **Opportunities**: Automation potential identification
- **Roadmap**: Priority improvements and implementation plan
```

Focus on actionable recommendations, cite specific tools/configurations where possible, and prioritize high-impact improvements for incident response effectiveness.